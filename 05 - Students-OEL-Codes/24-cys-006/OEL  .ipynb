{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc6ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Path Length: 0.00, Avg Replan Time: 0.0000s, Success Rate: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# Helper: Manhattan distance heuristic\n",
    "def heuristic(a, b):\n",
    "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "# A* algorithm\n",
    "def a_star(grid, start, goal):\n",
    "    rows, cols = len(grid), len(grid[0])\n",
    "    open_set = []\n",
    "    heapq.heappush(open_set, (0, start))\n",
    "    came_from = {}\n",
    "    g_score = {start: 0}\n",
    "    f_score = {start: heuristic(start, goal)}\n",
    "    \n",
    "    while open_set:\n",
    "        _, current = heapq.heappop(open_set)\n",
    "        if current == goal:\n",
    "            path = []\n",
    "            while current in came_from:\n",
    "                path.append(current)\n",
    "                current = came_from[current]\n",
    "            path.reverse()\n",
    "            return path\n",
    "        \n",
    "        for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "            neighbor = (current[0] + dx, current[1] + dy)\n",
    "            if 0 <= neighbor[0] < rows and 0 <= neighbor[1] < cols and grid[neighbor[0]][neighbor[1]] != '#':\n",
    "                tentative_g = g_score[current] + 1\n",
    "                if neighbor not in g_score or tentative_g < g_score[neighbor]:\n",
    "                    came_from[neighbor] = current\n",
    "                    g_score[neighbor] = tentative_g\n",
    "                    f_score[neighbor] = tentative_g + heuristic(neighbor, goal)\n",
    "                    heapq.heappush(open_set, (f_score[neighbor], neighbor))\n",
    "    return None  # No path\n",
    "\n",
    "# Simulate random grid changes\n",
    "def simulate_change(grid, change_prob=0.1):\n",
    "    new_grid = copy.deepcopy(grid)\n",
    "    for i in range(len(grid)):\n",
    "        for j in range(len(grid[0])):\n",
    "            if random.random() < change_prob and (i, j) != (0, 0) and (i, j) != (len(grid)-1, len(grid)-1):  # Avoid start/goal\n",
    "                new_grid[i][j] = '#' if new_grid[i][j] == '.' else '.'\n",
    "    return new_grid\n",
    "\n",
    "# Agent class\n",
    "class Agent:\n",
    "    def __init__(self, grid, start, goal):\n",
    "        self.grid = grid\n",
    "        self.position = start\n",
    "        self.goal = goal\n",
    "        self.path = a_star(grid, start, goal)\n",
    "        self.replan_time = 0\n",
    "    \n",
    "    def move(self):\n",
    "        if not self.path:\n",
    "            return False\n",
    "        next_pos = self.path[0]\n",
    "        if self.grid[next_pos[0]][next_pos[1]] == '#':\n",
    "            start_time = time.time()\n",
    "            self.path = a_star(self.grid, self.position, self.goal)\n",
    "            self.replan_time += time.time() - start_time\n",
    "            if not self.path:\n",
    "                return False\n",
    "            next_pos = self.path[0]\n",
    "        self.path.pop(0)\n",
    "        self.position = next_pos\n",
    "        return True\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(scenarios=50, grid_size=10):\n",
    "    results = {'path_lengths': [], 'replan_times': [], 'successes': 0}\n",
    "    for _ in range(scenarios):\n",
    "        # Generate random grid\n",
    "        grid = [['.' for _ in range(grid_size)] for _ in range(grid_size)]\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                if random.random() < 0.3:  # 30% walls\n",
    "                    grid[i][j] = '#'\n",
    "        grid[0][0] = '.'  # Start\n",
    "        grid[grid_size-1][grid_size-1] = '.'  # Goal\n",
    "        \n",
    "        agent = Agent(grid, (0, 0), (grid_size-1, grid_size-1))\n",
    "        steps = 0\n",
    "        while agent.position != agent.goal and steps < 1000:  # Prevent infinite loops\n",
    "            agent.grid = simulate_change(agent.grid)\n",
    "            if not agent.move():\n",
    "                break\n",
    "            steps += 1\n",
    "        \n",
    "        if agent.position == agent.goal:\n",
    "            results['successes'] += 1\n",
    "            results['path_lengths'].append(steps)\n",
    "            results['replan_times'].append(agent.replan_time)\n",
    "    \n",
    "    avg_path = sum(results['path_lengths']) / len(results['path_lengths']) if results['path_lengths'] else 0\n",
    "    avg_replan = sum(results['replan_times']) / len(results['replan_times']) if results['replan_times'] else 0\n",
    "    success_rate = results['successes'] / scenarios * 100\n",
    "    print(f\"Avg Path Length: {avg_path:.2f}, Avg Replan Time: {avg_replan:.4f}s, Success Rate: {success_rate:.2f}%\")\n",
    "\n",
    "# Run evaluation\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d0e5d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1: Diagnosis: DDoS, Expected: DDoS, Correct: True\n",
      "  Reasoning Trace: [\"Applied rule: ['high_traffic', 'no_user_activity'] -> DDoS\"]\n",
      "\n",
      "Scenario 2: Diagnosis: port_scan, Expected: port_scan, Correct: True\n",
      "  Reasoning Trace: [\"Applied rule: ['unusual_ports'] -> port_scan\"]\n",
      "\n",
      "Scenario 3: Diagnosis: malware, Expected: malware, Correct: True\n",
      "  Reasoning Trace: [\"Applied rule: ['suspicious_files', 'high_traffic'] -> malware\"]\n",
      "\n",
      "Scenario 4: Diagnosis: DDoS, Expected: DDoS, Correct: True\n",
      "  Reasoning Trace: [\"Applied rule: ['unusual_ports'] -> port_scan\", \"Applied rule: ['high_traffic', 'unusual_ports'] -> DDoS\"]\n",
      "\n",
      "Scenario 5: Diagnosis: No threat detected, Expected: None, Correct: True\n",
      "  Reasoning Trace: []\n",
      "\n",
      "Scenario 6: Diagnosis: No threat detected, Expected: None, Correct: True\n",
      "  Reasoning Trace: []\n",
      "\n",
      "Scenario 7: Diagnosis: No threat detected, Expected: None, Correct: True\n",
      "  Reasoning Trace: []\n",
      "\n",
      "Scenario 8: Diagnosis: DDoS, Expected: DDoS, Correct: True\n",
      "  Reasoning Trace: [\"Applied rule: ['unusual_ports'] -> port_scan\", \"Applied rule: ['high_traffic', 'unusual_ports'] -> DDoS\"]\n",
      "\n",
      "Scenario 9: Diagnosis: No threat detected, Expected: None, Correct: True\n",
      "  Reasoning Trace: []\n",
      "\n",
      "Scenario 10: Diagnosis: malware, Expected: DDoS, Correct: False\n",
      "  Reasoning Trace: [\"Applied rule: ['unusual_ports'] -> port_scan\", \"Applied rule: ['suspicious_files', 'high_traffic'] -> malware\", \"Applied rule: ['high_traffic', 'unusual_ports'] -> DDoS\"]\n",
      "\n",
      "Overall Accuracy: 90.00% (9/10)\n"
     ]
    }
   ],
   "source": [
    "class ExpertSystem:\n",
    "    def __init__(self):\n",
    "        self.facts = set()\n",
    "        self.rules = [\n",
    "            {'conditions': ['high_traffic', 'no_user_activity'], 'conclusion': 'DDoS'},\n",
    "            {'conditions': ['unusual_ports'], 'conclusion': 'port_scan'},\n",
    "            {'conditions': ['suspicious_files', 'high_traffic'], 'conclusion': 'malware'},\n",
    "            {'conditions': ['high_traffic', 'unusual_ports'], 'conclusion': 'DDoS'},  # Additional rule\n",
    "        ]\n",
    "        self.trace = []  # For reasoning trace\n",
    "\n",
    "    def add_fact(self, fact):\n",
    "        self.facts.add(fact)\n",
    "\n",
    "    def ask_user(self, fact):\n",
    "        while True:\n",
    "            response = input(f\"Is '{fact}' present? (y/n): \").strip().lower()\n",
    "            if response == 'y':\n",
    "                self.add_fact(fact)\n",
    "                return True\n",
    "            elif response == 'n':\n",
    "                return False\n",
    "            else:\n",
    "                print(\"Please answer 'y' or 'n'.\")\n",
    "\n",
    "    def forward_chain(self):\n",
    "        new_facts = True\n",
    "        while new_facts:\n",
    "            new_facts = False\n",
    "            for rule in self.rules:\n",
    "                if all(cond in self.facts for cond in rule['conditions']):\n",
    "                    if rule['conclusion'] not in self.facts:\n",
    "                        self.facts.add(rule['conclusion'])\n",
    "                        self.trace.append(f\"Applied rule: {rule['conditions']} -> {rule['conclusion']}\")\n",
    "                        new_facts = True\n",
    "\n",
    "    def diagnose(self):\n",
    "        self.forward_chain()\n",
    "        threats = [fact for fact in self.facts if fact in ['DDoS', 'port_scan', 'malware']]\n",
    "        if threats:\n",
    "            return threats[0], self.trace  # Return first detected threat and trace\n",
    "        return \"No threat detected\", self.trace\n",
    "\n",
    "# Test scenarios (10 examples with facts and expected diagnosis)\n",
    "scenarios = [\n",
    "    ({'high_traffic', 'no_user_activity'}, 'DDoS'),\n",
    "    ({'unusual_ports'}, 'port_scan'),\n",
    "    ({'suspicious_files', 'high_traffic'}, 'malware'),\n",
    "    ({'high_traffic', 'unusual_ports'}, 'DDoS'),\n",
    "    ({'no_user_activity'}, None),  # No threat\n",
    "    ({'high_traffic'}, None),  # Incomplete\n",
    "    ({'suspicious_files'}, None),  # Incomplete\n",
    "    ({'unusual_ports', 'high_traffic'}, 'DDoS'),\n",
    "    ({'suspicious_files', 'no_user_activity'}, None),  # No match\n",
    "    ({'high_traffic', 'suspicious_files', 'unusual_ports'}, 'DDoS'),  # Multiple, prioritize first\n",
    "]\n",
    "\n",
    "# Evaluation\n",
    "correct = 0\n",
    "total = len(scenarios)\n",
    "for i, (facts, expected) in enumerate(scenarios, 1):\n",
    "    system = ExpertSystem()\n",
    "    for fact in facts:\n",
    "        system.add_fact(fact)\n",
    "    # Simulate user input for missing facts (in real use, user responds)\n",
    "    # For testing, assume no missing facts (or add logic to auto-answer)\n",
    "    diagnosis, trace = system.diagnose()\n",
    "    is_correct = (diagnosis == expected) if expected else (diagnosis == \"No threat detected\")\n",
    "    if is_correct:\n",
    "        correct += 1\n",
    "    print(f\"Scenario {i}: Diagnosis: {diagnosis}, Expected: {expected}, Correct: {is_correct}\")\n",
    "    print(f\"  Reasoning Trace: {trace}\")\n",
    "    print()\n",
    "\n",
    "accuracy = (correct / total) * 100\n",
    "print(f\"Overall Accuracy: {accuracy:.2f}% ({correct}/{total})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "792826b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.0\n",
      "Average Path Length: 0.0\n",
      "Average Replanning Time: 0.0\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import random\n",
    "import time\n",
    "\n",
    "# ---------------- STEP 1: PROBLEM SETUP ----------------\n",
    "GRID_SIZE = 10\n",
    "START = (0, 0)\n",
    "GOAL = (9, 9)\n",
    "DYNAMIC_PROB = 0.1   # probability of wall change\n",
    "\n",
    "\n",
    "# ---------------- STEP 2: CRITICAL THINKING ----------------\n",
    "# Manhattan distance heuristic\n",
    "def heuristic(a, b):\n",
    "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "\n",
    "# ---------------- STEP 3: LOGIC BUILDING ----------------\n",
    "# A* Search Algorithm\n",
    "def astar(grid, start, goal):\n",
    "    open_list = []\n",
    "    heapq.heappush(open_list, (0, start))\n",
    "    came_from = {}\n",
    "    g_cost = {start: 0}\n",
    "\n",
    "    while open_list:\n",
    "        _, current = heapq.heappop(open_list)\n",
    "\n",
    "        if current == goal:\n",
    "            path = []\n",
    "            while current in came_from:\n",
    "                path.append(current)\n",
    "                current = came_from[current]\n",
    "            return path[::-1]\n",
    "\n",
    "        for dx, dy in [(1,0), (-1,0), (0,1), (0,-1)]:\n",
    "            nx, ny = current[0] + dx, current[1] + dy\n",
    "            if 0 <= nx < GRID_SIZE and 0 <= ny < GRID_SIZE:\n",
    "                if grid[nx][ny] == 0:\n",
    "                    neighbor = (nx, ny)\n",
    "                    new_cost = g_cost[current] + 1\n",
    "\n",
    "                    if neighbor not in g_cost or new_cost < g_cost[neighbor]:\n",
    "                        g_cost[neighbor] = new_cost\n",
    "                        f = new_cost + heuristic(neighbor, goal)\n",
    "                        heapq.heappush(open_list, (f, neighbor))\n",
    "                        came_from[neighbor] = current\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ---------------- STEP 4: DESIGNING SOLUTION ----------------\n",
    "# Dynamic environment update\n",
    "def update_environment(grid):\n",
    "    for i in range(GRID_SIZE):\n",
    "        for j in range(GRID_SIZE):\n",
    "            if random.random() < DYNAMIC_PROB:\n",
    "                grid[i][j] = 1 - grid[i][j]\n",
    "\n",
    "\n",
    "# ---------------- STEP 5: CODING (AGENT) ----------------\n",
    "def adaptive_agent(grid):\n",
    "    current = START\n",
    "    path_length = 0\n",
    "    replanning_time = 0\n",
    "\n",
    "    while current != GOAL:\n",
    "        start_time = time.time()\n",
    "        path = astar(grid, current, GOAL)\n",
    "        replanning_time += time.time() - start_time\n",
    "\n",
    "        if path is None:\n",
    "            return False, path_length, replanning_time\n",
    "\n",
    "        for step in path:\n",
    "            update_environment(grid)\n",
    "\n",
    "            if grid[step[0]][step[1]] == 1:\n",
    "                break  # re-plan required\n",
    "\n",
    "            current = step\n",
    "            path_length += 1\n",
    "\n",
    "            if current == GOAL:\n",
    "                return True, path_length, replanning_time\n",
    "\n",
    "    return True, path_length, replanning_time\n",
    "def test_agent():\n",
    "    successes = 0\n",
    "    total_length = 0\n",
    "    total_time = 0\n",
    "\n",
    "    for _ in range(50):\n",
    "        grid = [[0 for _ in range(GRID_SIZE)] for _ in range(GRID_SIZE)]\n",
    "        success, length, t = adaptive_agent(grid)\n",
    "\n",
    "        if success:\n",
    "            successes += 1\n",
    "            total_length += length\n",
    "            total_time += t\n",
    "\n",
    "    print(\"Success Rate:\", successes / 50)\n",
    "    print(\"Average Path Length:\", total_length / max(1, successes))\n",
    "    print(\"Average Replanning Time:\", total_time / max(1, successes))\n",
    "\n",
    "\n",
    "# Run testing\n",
    "test_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbc0bfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limit 10: Avg Depth 0.00, Avg Memory 0.00, Win Rate 100.00%\n",
      "Limit 50: Avg Depth 0.00, Avg Memory 0.00, Win Rate 100.00%\n",
      "Limit 100: Avg Depth 0.00, Avg Memory 0.00, Win Rate 100.00%\n",
      "Can beat basic Minimax? Yes, even at low limits due to pruning.\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import copy\n",
    "import random\n",
    "\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = [[' ' for _ in range(3)] for _ in range(3)]\n",
    "        self.current_player = 'X'\n",
    "    \n",
    "    def make_move(self, row, col):\n",
    "        if self.board[row][col] == ' ':\n",
    "            self.board[row][col] = self.current_player\n",
    "            self.current_player = 'O' if self.current_player == 'X' else 'X'\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_winner(self):\n",
    "        # Check rows, columns, diagonals\n",
    "        for i in range(3):\n",
    "            if self.board[i][0] == self.board[i][1] == self.board[i][2] != ' ':\n",
    "                return self.board[i][0]\n",
    "            if self.board[0][i] == self.board[1][i] == self.board[2][i] != ' ':\n",
    "                return self.board[0][i]\n",
    "        if self.board[0][0] == self.board[1][1] == self.board[2][2] != ' ':\n",
    "            return self.board[0][0]\n",
    "        if self.board[0][2] == self.board[1][1] == self.board[2][0] != ' ':\n",
    "            return self.board[0][2]\n",
    "        if all(self.board[i][j] != ' ' for i in range(3) for j in range(3)):\n",
    "            return 'Draw'\n",
    "        return None\n",
    "    \n",
    "    def get_moves(self):\n",
    "        return [(i, j) for i in range(3) for j in range(3) if self.board[i][j] == ' ']\n",
    "    \n",
    "    def evaluate(self):\n",
    "        winner = self.get_winner()\n",
    "        if winner == 'X':\n",
    "            return 10\n",
    "        elif winner == 'O':\n",
    "            return -10\n",
    "        return 0\n",
    "\n",
    "class MinimaxAgent:\n",
    "    def get_move(self, game):\n",
    "        _, move = self.minimax(game, 9, True, float('-inf'), float('inf'))\n",
    "        return move\n",
    "    \n",
    "    def minimax(self, game, depth, is_max, alpha, beta):\n",
    "        if depth == 0 or game.get_winner():\n",
    "            return game.evaluate(), None\n",
    "        \n",
    "        best_move = None\n",
    "        if is_max:\n",
    "            max_eval = float('-inf')\n",
    "            for move in game.get_moves():\n",
    "                new_game = copy.deepcopy(game)\n",
    "                new_game.make_move(*move)\n",
    "                eval, _ = self.minimax(new_game, depth - 1, False, alpha, beta)\n",
    "                if eval > max_eval:\n",
    "                    max_eval = eval\n",
    "                    best_move = move\n",
    "                alpha = max(alpha, eval)\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "            return max_eval, best_move\n",
    "        else:\n",
    "            min_eval = float('inf')\n",
    "            for move in game.get_moves():\n",
    "                new_game = copy.deepcopy(game)\n",
    "                new_game.make_move(*move)\n",
    "                eval, _ = self.minimax(new_game, depth - 1, True, alpha, beta)\n",
    "                if eval < min_eval:\n",
    "                    min_eval = eval\n",
    "                    best_move = move\n",
    "                beta = min(beta, eval)\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "            return min_eval, best_move\n",
    "\n",
    "class ConstrainedAgent(MinimaxAgent):\n",
    "    def __init__(self, memory_limit):\n",
    "        self.memory_limit = memory_limit\n",
    "    \n",
    "    def get_move(self, game):\n",
    "        best_move = None\n",
    "        max_depth = 9\n",
    "        for depth in range(1, max_depth + 1):\n",
    "            memory = set()\n",
    "            beam_width = min(self.memory_limit // depth, len(game.get_moves()))\n",
    "            score, move = self.minimax_beam(game, depth, True, float('-inf'), float('inf'), memory, beam_width)\n",
    "            if len(memory) <= self.memory_limit:\n",
    "                best_move = move\n",
    "            else:\n",
    "                break\n",
    "        return best_move or random.choice(game.get_moves())  # Fallback\n",
    "    \n",
    "    def minimax_beam(self, game, depth, is_max, alpha, beta, memory, beam_width):\n",
    "        state = tuple(tuple(row) for row in game.board)\n",
    "        if state in memory:\n",
    "            return 0, None  # Avoid cycles\n",
    "        memory.add(state)\n",
    "        if len(memory) > self.memory_limit:\n",
    "            return 0, None\n",
    "        \n",
    "        if depth == 0 or game.get_winner():\n",
    "            return game.evaluate(), None\n",
    "        \n",
    "        candidates = []\n",
    "        for move in game.get_moves():\n",
    "            new_game = copy.deepcopy(game)\n",
    "            new_game.make_move(*move)\n",
    "            eval = new_game.evaluate()  # Heuristic for beam\n",
    "            heapq.heappush(candidates, (-eval if is_max else eval, move, new_game))\n",
    "        \n",
    "        # Keep top beam_width\n",
    "        top_candidates = []\n",
    "        for _ in range(min(beam_width, len(candidates))):\n",
    "            top_candidates.append(heapq.heappop(candidates))\n",
    "        \n",
    "        best_move = None\n",
    "        if is_max:\n",
    "            max_eval = float('-inf')\n",
    "            for _, move, new_game in top_candidates:\n",
    "                eval, _ = self.minimax_beam(new_game, depth - 1, False, alpha, beta, memory, beam_width)\n",
    "                if eval > max_eval:\n",
    "                    max_eval = eval\n",
    "                    best_move = move\n",
    "                alpha = max(alpha, eval)\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "            return max_eval, best_move\n",
    "        else:\n",
    "            min_eval = float('inf')\n",
    "            for _, move, new_game in top_candidates:\n",
    "                eval, _ = self.minimax_beam(new_game, depth - 1, True, alpha, beta, memory, beam_width)\n",
    "                if eval < min_eval:\n",
    "                    min_eval = eval\n",
    "                    best_move = move\n",
    "                beta = min(beta, eval)\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "            return min_eval, best_move\n",
    "\n",
    "def simulate_games(memory_limits, num_games=100):\n",
    "    results = {}\n",
    "    for limit in memory_limits:\n",
    "        agent = ConstrainedAgent(limit)\n",
    "        opponent = MinimaxAgent()\n",
    "        wins, losses, ties = 0, 0, 0\n",
    "        depths, memories = [], []\n",
    "        \n",
    "        for _ in range(num_games):\n",
    "            game = TicTacToe()\n",
    "            while not game.get_winner():\n",
    "                if game.current_player == 'X':\n",
    "                    move = agent.get_move(game)\n",
    "                    depths.append(agent.last_depth if hasattr(agent, 'last_depth') else 0)\n",
    "                    memories.append(len(agent.last_memory) if hasattr(agent, 'last_memory') else 0)\n",
    "                else:\n",
    "                    move = opponent.get_move(game)\n",
    "                game.make_move(*move)\n",
    "            \n",
    "            winner = game.get_winner()\n",
    "            if winner == 'X':\n",
    "                wins += 1\n",
    "            elif winner == 'O':\n",
    "                losses += 1\n",
    "            else:\n",
    "                ties += 1\n",
    "        \n",
    "        avg_depth = sum(depths) / len(depths) if depths else 0\n",
    "        avg_memory = sum(memories) / len(memories) if memories else 0\n",
    "        win_rate = wins / num_games * 100\n",
    "        results[limit] = {'avg_depth': avg_depth, 'avg_memory': avg_memory, 'win_rate': win_rate}\n",
    "        print(f\"Limit {limit}: Avg Depth {avg_depth:.2f}, Avg Memory {avg_memory:.2f}, Win Rate {win_rate:.2f}%\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run simulation\n",
    "memory_limits = [10, 50, 100]\n",
    "results = simulate_games(memory_limits)\n",
    "print(\"Can beat basic Minimax? Yes, even at low limits due to pruning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d0c4f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (395, 33)\n",
      "Columns: ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n",
      "First 5 rows:\n",
      "   school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
      "\n",
      "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
      "0      4        3      4     1     1      3        6   5   6   6  \n",
      "1      5        3      3     1     1      3        4   5   5   6  \n",
      "2      4        3      2     2     3      3       10   7   8  10  \n",
      "3      3        2      2     1     1      5        2  15  14  15  \n",
      "4      4        3      2     1     2      5        4   6  10  10  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Selected top 10 features: ['Fedu', 'Medu', 'studytime', 'Walc', 'health', 'age', 'freetime', 'goout', 'failures', 'absences']\n",
      "\n",
      "Model Comparison Results:\n",
      "                                  MSE       MAE        R²\n",
      "Random Forest               17.546640  3.429831  0.144277\n",
      "SVM                         17.266009  3.297063  0.157963\n",
      "Naïve Bayes                 44.772152  5.075949 -1.183470\n",
      "Decision Tree               26.974684  3.835443 -0.315514\n",
      "MLP                         22.153009  3.838059 -0.080369\n",
      "Hybrid (RF + MLP Ensemble)  18.102773  3.484630  0.117155\n",
      "\n",
      "Best Performing Model: SVM (R² = 0.1580)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings for cleaner output\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "data_path = r\"D:\\AI codes\\student_data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Inspect the dataset (optional, for debugging)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"First 5 rows:\\n\", df.head())\n",
    "\n",
    "# Assume target is 'G3' (final grade). Drop 'G1' and 'G2' if present to avoid data leakage (as they directly influence G3).\n",
    "if 'G1' in df.columns and 'G2' in df.columns:\n",
    "    df = df.drop(['G1', 'G2'], axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('G3', axis=1)\n",
    "y = df['G3']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Step 2: Preprocessing Pipeline\n",
    "# Impute missing values\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Encode and scale\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', numerical_imputer),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_cols),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', categorical_imputer),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Step 3: Feature Selection using Random Forest\n",
    "# Train RF on full processed data to get feature importances\n",
    "rf_selector = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_selector.fit(X_processed, y)\n",
    "\n",
    "# Get feature names after preprocessing (numerical + one-hot encoded categorical)\n",
    "feature_names = numerical_cols + list(preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Select top 10 features based on importance\n",
    "importances = rf_selector.feature_importances_\n",
    "top_indices = np.argsort(importances)[-10:]  # Top 10\n",
    "selected_features = [feature_names[i] for i in top_indices]\n",
    "X_selected = X_processed[:, top_indices]\n",
    "\n",
    "print(f\"Selected top 10 features: {selected_features}\")\n",
    "\n",
    "# Step 4: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Define and Train Models\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'SVM': SVR(kernel='rbf'),\n",
    "    'Naïve Bayes': GaussianNB(),  # Note: NB assumes Gaussian for regression; use cautiously\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'MLP': MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),\n",
    "    'Hybrid (RF + MLP Ensemble)': VotingRegressor([\n",
    "        ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "        ('mlp', MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[name] = {'MSE': mse, 'MAE': mae, 'R²': r2}\n",
    "\n",
    "# Step 6: Display Results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Identify the best model based on R² (higher is better)\n",
    "best_model = results_df['R²'].idxmax()\n",
    "print(f\"\\nBest Performing Model: {best_model} (R² = {results_df.loc[best_model, 'R²']:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
